# use a clean base URL (no trailing slash)
export OPENAI_API_BASE=https://ixxxxx/xxxxx/v1 # -> https://.../v1
export OPENAI_API_KEY=eyJxxxxxxxx4
export DEFAULT_MODEL=llama3_1_8b_instruct # the model name should be as per the name provider has given
export PROVIDER_NAME=e2e # vendor/provider name; eg. together, nebius etc.

# tells vLLM which tokenizer to use for fair token counts
# you need HF access to Meta Llama 3.1 tokenizer
export TOKENIZER="meta-llama/Meta-Llama-3.1-8B-Instruct"
